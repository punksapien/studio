-- Universal Sync Trigger System - Phase 3: Meta-Inspired Observability & Performance Optimization
-- Migration: 20250115000011_phase3_observability_corrected.sql
-- Based on Meta TAO (The Associations and Objects) system design patterns

-- =============================================================================
-- 1. ADVANCED PERFORMANCE MONITORING (Meta TAO Inspired)
-- =============================================================================

-- Create performance metrics table for detailed analytics
CREATE TABLE sync_performance_metrics (
  id BIGSERIAL PRIMARY KEY,
  metric_name VARCHAR(100) NOT NULL,
  metric_value NUMERIC NOT NULL,
  metric_type VARCHAR(50) NOT NULL, -- 'latency', 'throughput', 'error_rate', 'cache_hit_ratio'
  event_type VARCHAR(50),
  source_table VARCHAR(50),
  target_table VARCHAR(50),
  recorded_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  additional_context JSONB DEFAULT '{}'
);

-- Indexes for efficient metrics querying
CREATE INDEX idx_perf_metrics_name_time ON sync_performance_metrics(metric_name, recorded_at DESC);
CREATE INDEX idx_perf_metrics_type_time ON sync_performance_metrics(metric_type, recorded_at DESC);
CREATE INDEX idx_perf_metrics_tables ON sync_performance_metrics(source_table, target_table, recorded_at DESC);

-- Create sync operation latency tracking
CREATE TABLE sync_latency_traces (
  id BIGSERIAL PRIMARY KEY,
  sync_event_id BIGINT REFERENCES sync_events(id) ON DELETE CASCADE,
  operation_phase VARCHAR(50) NOT NULL, -- 'trigger_start', 'rule_lookup', 'execution', 'completion'
  phase_start_time TIMESTAMP WITH TIME ZONE NOT NULL,
  phase_end_time TIMESTAMP WITH TIME ZONE,
  phase_duration_ms INTEGER,
  memory_usage_kb INTEGER,
  cpu_time_ms INTEGER,
  context_data JSONB DEFAULT '{}'
);

-- Index for latency analysis
CREATE INDEX idx_latency_traces_event_phase ON sync_latency_traces(sync_event_id, operation_phase);
CREATE INDEX idx_latency_traces_duration ON sync_latency_traces(phase_duration_ms DESC) WHERE phase_duration_ms IS NOT NULL;

-- =============================================================================
-- 2. META TAO-INSPIRED CACHING LAYER
-- =============================================================================

-- Create sync result cache (similar to Meta TAO read-through cache)
CREATE TABLE sync_cache_entries (
  id BIGSERIAL PRIMARY KEY,
  cache_key VARCHAR(500) NOT NULL UNIQUE,
  cache_value JSONB NOT NULL,
  cache_type VARCHAR(50) NOT NULL, -- 'count_result', 'status_lookup', 'rule_config'
  source_table VARCHAR(50),
  source_id UUID,
  expires_at TIMESTAMP WITH TIME ZONE NOT NULL,
  hit_count INTEGER DEFAULT 0,
  last_accessed TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes for cache performance
CREATE INDEX idx_cache_key_expires ON sync_cache_entries(cache_key, expires_at);
CREATE INDEX idx_cache_source_expires ON sync_cache_entries(source_table, source_id, expires_at);
CREATE INDEX idx_cache_type_expires ON sync_cache_entries(cache_type, expires_at);

-- =============================================================================
-- 3. CIRCUIT BREAKER PATTERN (For External Service Reliability)
-- =============================================================================

-- Create circuit breaker state tracking
CREATE TABLE sync_circuit_breakers (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  service_name VARCHAR(100) NOT NULL UNIQUE,
  state VARCHAR(20) DEFAULT 'CLOSED', -- 'CLOSED', 'OPEN', 'HALF_OPEN'
  failure_count INTEGER DEFAULT 0,
  success_count INTEGER DEFAULT 0,
  last_failure_time TIMESTAMP WITH TIME ZONE,
  last_success_time TIMESTAMP WITH TIME ZONE,
  failure_threshold INTEGER DEFAULT 5,
  recovery_timeout_seconds INTEGER DEFAULT 60,
  half_open_max_calls INTEGER DEFAULT 3,
  state_changed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  configuration JSONB DEFAULT '{}'
);

-- Create circuit breaker events log
CREATE TABLE sync_circuit_breaker_events (
  id BIGSERIAL PRIMARY KEY,
  circuit_breaker_id UUID REFERENCES sync_circuit_breakers(id) ON DELETE CASCADE,
  event_type VARCHAR(50) NOT NULL, -- 'FAILURE', 'SUCCESS', 'STATE_CHANGE', 'THRESHOLD_EXCEEDED'
  previous_state VARCHAR(20),
  new_state VARCHAR(20),
  error_details TEXT,
  recorded_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- =============================================================================
-- 4. ADVANCED ALERTING SYSTEM
-- =============================================================================

-- Create alerting rules configuration
CREATE TABLE sync_alert_rules (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  rule_name VARCHAR(200) NOT NULL,
  alert_type VARCHAR(50) NOT NULL, -- 'PERFORMANCE_DEGRADATION', 'ERROR_RATE_HIGH', 'CIRCUIT_BREAKER_OPEN'
  condition_expression TEXT NOT NULL, -- SQL-like expression for alert condition
  severity VARCHAR(20) DEFAULT 'MEDIUM', -- 'LOW', 'MEDIUM', 'HIGH', 'CRITICAL'
  evaluation_interval_seconds INTEGER DEFAULT 60,
  consecutive_breaches_required INTEGER DEFAULT 2,
  alert_channels JSONB DEFAULT '[]', -- ['email', 'slack', 'webhook']
  is_active BOOLEAN DEFAULT true,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Create active alerts tracking
CREATE TABLE sync_active_alerts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  alert_rule_id UUID REFERENCES sync_alert_rules(id) ON DELETE CASCADE,
  alert_level VARCHAR(20) NOT NULL,
  alert_message TEXT NOT NULL,
  alert_data JSONB DEFAULT '{}',
  triggered_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  acknowledged_at TIMESTAMP WITH TIME ZONE,
  resolved_at TIMESTAMP WITH TIME ZONE,
  escalation_level INTEGER DEFAULT 0
);

-- =============================================================================
-- 5. ENHANCED WEBHOOK SYSTEM (Fixed Type Issue)
-- =============================================================================

-- Fix the webhook deliveries table with correct foreign key type
DROP TABLE IF EXISTS sync_webhook_deliveries;
CREATE TABLE sync_webhook_deliveries (
  id BIGSERIAL PRIMARY KEY,
  webhook_endpoint_id UUID REFERENCES sync_webhook_endpoints(id) ON DELETE CASCADE,
  sync_event_id BIGINT REFERENCES sync_events(id) ON DELETE CASCADE, -- Fixed: BIGINT to match sync_events.id
  payload JSONB NOT NULL,
  http_status_code INTEGER,
  response_body TEXT,
  delivery_status VARCHAR(20) DEFAULT 'pending', -- pending, success, failed, retrying
  retry_count INTEGER DEFAULT 0,
  delivered_at TIMESTAMP WITH TIME ZONE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Index for webhook delivery tracking
CREATE INDEX idx_webhook_deliveries_status ON sync_webhook_deliveries(delivery_status, created_at);
CREATE INDEX idx_webhook_deliveries_sync_event ON sync_webhook_deliveries(sync_event_id);

-- =============================================================================
-- 6. PERFORMANCE OPTIMIZATION FUNCTIONS
-- =============================================================================

-- Function to record performance metrics (Meta TAO style)
CREATE OR REPLACE FUNCTION record_sync_metric(
  p_metric_name VARCHAR(100),
  p_metric_value NUMERIC,
  p_metric_type VARCHAR(50),
  p_event_type VARCHAR(50) DEFAULT NULL,
  p_source_table VARCHAR(50) DEFAULT NULL,
  p_target_table VARCHAR(50) DEFAULT NULL,
  p_context JSONB DEFAULT '{}'
)
RETURNS VOID AS $$
BEGIN
  INSERT INTO sync_performance_metrics (
    metric_name, metric_value, metric_type, event_type,
    source_table, target_table, additional_context
  ) VALUES (
    p_metric_name, p_metric_value, p_metric_type, p_event_type,
    p_source_table, p_target_table, p_context
  );
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Enhanced cache-aware sync execution (Meta TAO inspired)
CREATE OR REPLACE FUNCTION get_cached_count(
  p_table_name VARCHAR(50),
  p_record_id UUID,
  p_count_field VARCHAR(50)
)
RETURNS INTEGER AS $$
DECLARE
  cache_key VARCHAR(500);
  cached_result INTEGER;
  fresh_result INTEGER;
  cache_expiry TIMESTAMP WITH TIME ZONE;
BEGIN
  -- Generate cache key
  cache_key := format('count_%s_%s_%s', p_table_name, p_record_id, p_count_field);

  -- Try to get from cache first
  SELECT
    (cache_value->>'value')::INTEGER,
    expires_at
  INTO cached_result, cache_expiry
  FROM sync_cache_entries
  WHERE cache_key = get_cached_count.cache_key
    AND expires_at > NOW();

  IF cached_result IS NOT NULL THEN
    -- Update hit count
    UPDATE sync_cache_entries
    SET hit_count = hit_count + 1, last_accessed = NOW()
    WHERE cache_key = get_cached_count.cache_key;

    -- Record cache hit metric
    PERFORM record_sync_metric('cache_hit', 1, 'cache_hit_ratio', 'count_lookup', p_table_name);

    RETURN cached_result;
  END IF;

  -- Cache miss - get fresh value
  EXECUTE format('SELECT COALESCE(%I, 0) FROM %I WHERE id = $1', p_count_field, p_table_name)
  INTO fresh_result USING p_record_id;

  -- Store in cache (5 minute expiry)
  INSERT INTO sync_cache_entries (
    cache_key, cache_value, cache_type, source_table, source_id, expires_at
  ) VALUES (
    cache_key,
    jsonb_build_object('value', fresh_result),
    'count_result',
    p_table_name,
    p_record_id,
    NOW() + INTERVAL '5 minutes'
  ) ON CONFLICT (cache_key) DO UPDATE SET
    cache_value = EXCLUDED.cache_value,
    expires_at = EXCLUDED.expires_at,
    last_accessed = NOW();

  -- Record cache miss metric
  PERFORM record_sync_metric('cache_miss', 1, 'cache_hit_ratio', 'count_lookup', p_table_name);

  RETURN fresh_result;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Circuit breaker state management
CREATE OR REPLACE FUNCTION check_circuit_breaker(
  p_service_name VARCHAR(100)
)
RETURNS BOOLEAN AS $$
DECLARE
  breaker_record RECORD;
  is_allowed BOOLEAN := true;
BEGIN
  SELECT * INTO breaker_record
  FROM sync_circuit_breakers
  WHERE service_name = p_service_name;

  IF NOT FOUND THEN
    -- Create new circuit breaker in CLOSED state
    INSERT INTO sync_circuit_breakers (service_name) VALUES (p_service_name);
    RETURN true;
  END IF;

  CASE breaker_record.state
    WHEN 'CLOSED' THEN
      is_allowed := true;
    WHEN 'OPEN' THEN
      -- Check if recovery timeout has passed
      IF breaker_record.state_changed_at + (breaker_record.recovery_timeout_seconds || ' seconds')::INTERVAL < NOW() THEN
        -- Transition to HALF_OPEN
        UPDATE sync_circuit_breakers
        SET state = 'HALF_OPEN', state_changed_at = NOW()
        WHERE id = breaker_record.id;

        INSERT INTO sync_circuit_breaker_events (
          circuit_breaker_id, event_type, previous_state, new_state
        ) VALUES (
          breaker_record.id, 'STATE_CHANGE', 'OPEN', 'HALF_OPEN'
        );

        is_allowed := true;
      ELSE
        is_allowed := false;
      END IF;
    WHEN 'HALF_OPEN' THEN
      is_allowed := true;
  END CASE;

  RETURN is_allowed;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- =============================================================================
-- 7. PERFORMANCE ANALYSIS VIEWS
-- =============================================================================

-- Real-time performance dashboard (Meta TAO inspired)
CREATE VIEW sync_performance_dashboard AS
WITH recent_metrics AS (
  SELECT
    metric_name,
    metric_type,
    AVG(metric_value) as avg_value,
    MAX(metric_value) as max_value,
    MIN(metric_value) as min_value,
    COUNT(*) as sample_count,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY metric_value) as p95_value,
    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY metric_value) as p99_value
  FROM sync_performance_metrics
  WHERE recorded_at > NOW() - INTERVAL '1 hour'
  GROUP BY metric_name, metric_type
)
SELECT
  metric_name,
  metric_type,
  ROUND(avg_value::numeric, 2) as avg_value,
  ROUND(max_value::numeric, 2) as max_value,
  ROUND(min_value::numeric, 2) as min_value,
  sample_count,
  ROUND(p95_value::numeric, 2) as p95_value,
  ROUND(p99_value::numeric, 2) as p99_value
FROM recent_metrics
ORDER BY metric_type, metric_name;

-- Latency breakdown analysis
CREATE VIEW sync_latency_breakdown AS
SELECT
  se.event_type,
  se.source_table,
  se.target_table,
  COUNT(*) as operation_count,
  ROUND(AVG(se.processing_time_ms)::numeric, 2) as avg_total_latency_ms,
  ROUND(AVG(slt.phase_duration_ms) FILTER (WHERE slt.operation_phase = 'rule_lookup')::numeric, 2) as avg_rule_lookup_ms,
  ROUND(AVG(slt.phase_duration_ms) FILTER (WHERE slt.operation_phase = 'execution')::numeric, 2) as avg_execution_ms,
  ROUND(MAX(se.processing_time_ms)::numeric, 2) as max_total_latency_ms,
  PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY se.processing_time_ms) as p95_latency_ms
FROM sync_events se
LEFT JOIN sync_latency_traces slt ON se.id = slt.sync_event_id
WHERE se.created_at > NOW() - INTERVAL '24 hours'
GROUP BY se.event_type, se.source_table, se.target_table
ORDER BY avg_total_latency_ms DESC;

-- Cache performance analysis
CREATE VIEW sync_cache_performance AS
SELECT
  cache_type,
  source_table,
  COUNT(*) as total_entries,
  SUM(hit_count) as total_hits,
  ROUND(AVG(hit_count)::numeric, 2) as avg_hits_per_entry,
  COUNT(*) FILTER (WHERE expires_at > NOW()) as active_entries,
  COUNT(*) FILTER (WHERE expires_at <= NOW()) as expired_entries,
  ROUND(
    ((SUM(hit_count)::float / NULLIF(COUNT(*), 0)) * 100)::numeric, 2
  ) as hit_ratio_percent
FROM sync_cache_entries
GROUP BY cache_type, source_table
ORDER BY total_hits DESC;

-- =============================================================================
-- 8. AUTOMATIC OPTIMIZATION TRIGGERS
-- =============================================================================

-- Function to automatically optimize slow operations
CREATE OR REPLACE FUNCTION auto_optimize_sync_performance()
RETURNS VOID AS $$
DECLARE
  slow_operation RECORD;
  optimization_applied BOOLEAN := false;
BEGIN
  -- Find operations consistently slower than 1 second
  FOR slow_operation IN
    SELECT
      event_type, source_table, target_table,
      AVG(processing_time_ms) as avg_time,
      COUNT(*) as occurrences
    FROM sync_events
    WHERE created_at > NOW() - INTERVAL '1 hour'
      AND processing_time_ms > 1000
    GROUP BY event_type, source_table, target_table
    HAVING COUNT(*) >= 5 AND AVG(processing_time_ms) > 1000
  LOOP
    -- Log performance issue
    INSERT INTO sync_performance_metrics (
      metric_name, metric_value, metric_type, event_type, source_table, target_table
    ) VALUES (
      'slow_operation_detected', slow_operation.avg_time, 'performance_alert',
      slow_operation.event_type, slow_operation.source_table, slow_operation.target_table
    );

    -- Apply automatic optimizations based on operation type
    IF slow_operation.event_type = 'count_sync' THEN
      -- Extend cache TTL for slow count operations
      UPDATE sync_cache_entries
      SET expires_at = NOW() + INTERVAL '15 minutes'
      WHERE cache_type = 'count_result'
        AND source_table = slow_operation.source_table
        AND expires_at > NOW();

      optimization_applied := true;
    END IF;
  END LOOP;

  IF optimization_applied THEN
    PERFORM record_sync_metric('auto_optimization_applied', 1, 'optimization', 'performance_tuning');
  END IF;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- =============================================================================
-- 9. MONITORING DATA RETENTION & CLEANUP
-- =============================================================================

-- Function to clean up old performance data
CREATE OR REPLACE FUNCTION cleanup_performance_data()
RETURNS INTEGER AS $$
DECLARE
  deleted_count INTEGER := 0;
  total_deleted INTEGER := 0;
BEGIN
  -- Clean up old performance metrics (keep 30 days)
  DELETE FROM sync_performance_metrics
  WHERE recorded_at < NOW() - INTERVAL '30 days';
  GET DIAGNOSTICS deleted_count = ROW_COUNT;
  total_deleted := total_deleted + deleted_count;

  -- Clean up old latency traces (keep 7 days)
  DELETE FROM sync_latency_traces
  WHERE phase_start_time < NOW() - INTERVAL '7 days';
  GET DIAGNOSTICS deleted_count = ROW_COUNT;
  total_deleted := total_deleted + deleted_count;

  -- Clean up expired cache entries
  DELETE FROM sync_cache_entries
  WHERE expires_at < NOW() - INTERVAL '1 hour';
  GET DIAGNOSTICS deleted_count = ROW_COUNT;
  total_deleted := total_deleted + deleted_count;

  -- Clean up old circuit breaker events (keep 14 days)
  DELETE FROM sync_circuit_breaker_events
  WHERE recorded_at < NOW() - INTERVAL '14 days';
  GET DIAGNOSTICS deleted_count = ROW_COUNT;
  total_deleted := total_deleted + deleted_count;

  RETURN total_deleted;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- =============================================================================
-- 10. PERMISSIONS & SECURITY
-- =============================================================================

-- Grant read access to performance views
GRANT SELECT ON sync_performance_dashboard TO authenticated;
GRANT SELECT ON sync_latency_breakdown TO authenticated;
GRANT SELECT ON sync_cache_performance TO authenticated;

-- Grant limited access to performance data
GRANT SELECT ON sync_performance_metrics TO authenticated;
GRANT SELECT ON sync_circuit_breakers TO authenticated;
GRANT SELECT ON sync_active_alerts TO authenticated;

-- =============================================================================
-- 11. INITIALIZATION & SAMPLE ALERT RULES
-- =============================================================================

-- Insert default alert rules
INSERT INTO sync_alert_rules (rule_name, alert_type, condition_expression, severity, alert_channels) VALUES
('High Sync Latency', 'PERFORMANCE_DEGRADATION',
 'AVG(processing_time_ms) > 5000 IN LAST 5 MINUTES',
 'HIGH', '["email", "slack"]'),
('Sync Error Rate High', 'ERROR_RATE_HIGH',
 'ERROR_RATE > 0.05 IN LAST 10 MINUTES',
 'CRITICAL', '["email", "slack", "webhook"]'),
('Circuit Breaker Open', 'CIRCUIT_BREAKER_OPEN',
 'ANY circuit_breaker.state = OPEN',
 'HIGH', '["email", "slack"]'),
('Cache Hit Rate Low', 'PERFORMANCE_DEGRADATION',
 'CACHE_HIT_RATE < 0.8 IN LAST 15 MINUTES',
 'MEDIUM', '["email"]');

-- Initialize Phase 3 monitoring
DO $$
BEGIN
  -- Record that Phase 3 monitoring is initialized
  PERFORM record_sync_metric('phase3_initialized', 1, 'system_event', 'initialization');
END $$;

-- Migration complete message
DO $$
BEGIN
  RAISE NOTICE 'ðŸš€ Universal Sync Trigger System - Phase 3 (Meta-Inspired Observability) completed!';
  RAISE NOTICE '';
  RAISE NOTICE 'NEW META TAO-INSPIRED FEATURES:';
  RAISE NOTICE 'â€¢ Advanced performance metrics with P95/P99 latency tracking';
  RAISE NOTICE 'â€¢ Read-through caching layer for optimal performance';
  RAISE NOTICE 'â€¢ Circuit breaker pattern for external service reliability';
  RAISE NOTICE 'â€¢ Automatic performance optimization and alerting';
  RAISE NOTICE 'â€¢ Comprehensive latency breakdown analysis';
  RAISE NOTICE 'â€¢ Production-grade monitoring dashboards';
  RAISE NOTICE '';
  RAISE NOTICE 'MONITORING VIEWS AVAILABLE:';
  RAISE NOTICE 'â€¢ sync_performance_dashboard - Real-time P95/P99 metrics';
  RAISE NOTICE 'â€¢ sync_latency_breakdown - Phase-by-phase timing analysis';
  RAISE NOTICE 'â€¢ sync_cache_performance - Cache hit rates and optimization';
  RAISE NOTICE '';
  RAISE NOTICE 'AUTOMATIC OPTIMIZATIONS:';
  RAISE NOTICE 'â€¢ Cache TTL extension for slow operations';
  RAISE NOTICE 'â€¢ Circuit breaker protection for external services';
  RAISE NOTICE 'â€¢ Performance-based alerting and escalation';
  RAISE NOTICE '';
  RAISE NOTICE 'âœ… Phase 3 Complete - Meta-grade observability operational!';
END $$;
